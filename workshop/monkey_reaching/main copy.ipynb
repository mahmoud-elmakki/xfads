{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b81c5c88-d8c2-4b4f-a0ae-30038e78cdb3",
   "metadata": {},
   "source": [
    "# eXponential Family Dynamical Systems (XFADS): Large-scale nonlinear Gaussian state-space modeling\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/catniplab/xfads/blob/workshop/workshop/monkey_reaching/main.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "<br>Approximate inference targeted at variational Gaussian state-space models with dense covariance matrix approximations.  For more details, see our paper: [Dowling, Zhao, Park. 2024](https://arxiv.org/abs/2403.01371)\n",
    "\n",
    "This is a walk-through for the minimal functioning of XFADS. We will be building a toy model on the [MC_Maze](https://neurallatents.github.io/datasets.html) dataset as a benchmark, which is a delayed center-out reaching task with barriers.<br>\n",
    "With the adequate configs, you can fit XFADS on different spans of neural data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6276424f-2488-4214-8c83-9e2826657ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as lightning\n",
    "\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from mc_utils import *\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from xfads import plot_utils\n",
    "from xfads.smoothers.lightning_trainers import LightningMonkeyReaching\n",
    "from xfads.ssm_modules.prebuilt_models import create_xfads_poisson_log_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ae4e6-c0d2-41ae-838c-e84ad0aae6bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c55abd-d3bb-4692-ad46-d1a40918d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize(version_base=None, config_path=\"\", job_name=\"monkey_reaching\")\n",
    "cfg = compose(config_name=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e19a4a-7edb-4b85-a8bb-314d35836deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning.seed_everything(cfg.seed, workers=True)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f923cdc-62c6-4bbb-916b-bdf4f7d1690d",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "The data is already in the GitHub repo; so it should've been downloaded (in `./data`) with the clone. But if you want to download it manullay, run `download_data.py`. Or you can download it directly from DANDI: [MC_Maze_Medium](https://dandiarchive.org/dandiset/000139)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942e4f1-d781-4332-aced-53464f768240",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/data_{split}_{bin_sz_ms}ms.pt'\n",
    "train_data = torch.load(data_path.format(split='train', bin_sz_ms=cfg.bin_sz_ms))\n",
    "val_data = torch.load(data_path.format(split='valid', bin_sz_ms=cfg.bin_sz_ms))\n",
    "test_data = torch.load(data_path.format(split='test', bin_sz_ms=cfg.bin_sz_ms))\n",
    "\n",
    "y_train_obs = train_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "y_valid_obs = val_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "y_test_obs = test_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "\n",
    "vel_train = train_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_valid = val_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_test = test_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "\n",
    "y_train_dataset = torch.utils.data.TensorDataset(y_train_obs, vel_train)\n",
    "y_val_dataset = torch.utils.data.TensorDataset(y_valid_obs, vel_valid)\n",
    "y_test_dataset = torch.utils.data.TensorDataset(y_test_obs, vel_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(y_train_dataset, batch_size=cfg.batch_sz, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(y_val_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(y_test_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)\n",
    "\n",
    "# Data dimensions\n",
    "n_train_trials, n_time_bins, n_neurons_obs = y_train_obs.shape\n",
    "n_valid_trials = y_valid_obs.shape[0]\n",
    "n_test_trials = y_test_obs.shape[0]\n",
    "n_time_bins_enc = train_data['n_time_bins_enc']\n",
    "\n",
    "n_bins_bhv = 10  # at t=n_bins_bhv start forecast\n",
    "move_onset = 12  # stimulus onset\n",
    "\n",
    "trial_list=[1, 287//4, 28//4 + 287//2, 286]\n",
    "\n",
    "print(\"# training trials: {0}\".format(n_train_trials))\n",
    "print(\"# validation trials: {0}\".format(n_valid_trials))\n",
    "print(\"# testing trials: {0}\".format(n_test_trials))\n",
    "print(\"# neurons: {0}\".format(n_neurons_obs))\n",
    "print(\"# time bins: {0}\".format(n_time_bins))\n",
    "print(\"# time bins used for forcasting: {0}\".format(n_bins_bhv))\n",
    "print(\"# predicted time bins: {0}\".format(n_time_bins_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f317d-1892-463c-af02-79ed910ab423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4edd3-23e4-4c0f-96c3-e5004c1a5756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e9b68-af45-4be8-b11a-9d449740cc0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad592b73-4d0f-485a-a681-aba7d5d74ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data['y_obs'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3705019-2737-4f80-aa0a-270bfecfd9d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Structuring the State-Space Model\n",
    "\n",
    "The configuration depends on the problem - `dynamics_mod`, `initial_c_pdf`, `likelihood_pdf`, `local_encoder`, and `backward_encoder` can be configured as desired. We include some general classes in `ssm_modules/encoders`, `ssm_modules/likelihoods` and `ssm_modules/dynamics` that should be sufficient for a wide range of problems.  Below is an example configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01082bb9-e57d-4a8c-a134-e0eba4946d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"create ssm\"\"\"\n",
    "ssm = create_xfads_poisson_log_link(cfg, n_neurons_obs, train_dataloader, model_type='n')\n",
    "\n",
    "\"\"\"lightning\"\"\"\n",
    "seq_vae = LightningMonkeyReaching(ssm, cfg, n_time_bins_enc, n_bins_bhv)\n",
    "csv_logger = CSVLogger('logs/smoother/acausal/', name=f'sd_{cfg.seed}_r_y_{cfg.rank_local}_r_b_{cfg.rank_backward}', version='smoother_acausal')\n",
    "ckpt_callback = ModelCheckpoint(save_top_k=3, monitor='r2_valid_enc', mode='max', dirpath='ckpts/smoother/acausal/', save_last=True,\n",
    "                                filename='{epoch:0}_{valid_loss:0.2f}_{r2_valid_enc:0.2f}_{r2_valid_bhv:0.2f}_{valid_bps_enc:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7880b37-078b-4024-87b3-0af955b0d937",
   "metadata": {},
   "source": [
    "## Training and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614378d-3bf3-4954-b532-c0e6f37d4f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = lightning.Trainer(max_epochs=cfg.n_epochs,\n",
    "                            gradient_clip_val=1.0,\n",
    "                            default_root_dir='lightning/',\n",
    "                            callbacks=[ckpt_callback],\n",
    "                            logger=csv_logger,\n",
    "                            )\n",
    "\n",
    "trainer.fit(model=seq_vae, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)\n",
    "torch.save(ckpt_callback.best_model_path, 'ckpts/smoother/acausal/best_model_path.pt')\n",
    "trainer.test(dataloaders=test_dataloader, ckpt_path='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462841f6-257e-4d17-bfb6-47f56c99db05",
   "metadata": {},
   "source": [
    "## Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e68479-0d95-4cb4-8729-3ad1ee949815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"lightning\"\"\"\n",
    "model_ckpt_path = 'ckpts/smoother/acausal/best_model_path.pt'\n",
    "seq_vae = LightningMonkeyReaching.load_from_checkpoint(model_ckpt_path, ssm=ssm, cfg=cfg,\n",
    "                                                       n_time_bins_enc=n_time_bins_enc, n_time_bins_bhv=n_bins_bhv,\n",
    "                                                       strict=False)\n",
    "\"\"\"extract trained ssm from lightning module\"\"\"\n",
    "seq_vae.ssm = seq_vae.ssm.to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f58c0e-ddc9-4354-a593-f3e1e739d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_s_train = []\n",
    "z_s_valid = []\n",
    "z_f_valid = []\n",
    "z_p_valid = []\n",
    "stats_valid = []\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    \n",
    "    loss, z, stats = seq_vae.ssm(batch[0], cfg.n_samples)\n",
    "    z_s_train.append(z)\n",
    "\n",
    "for batch in valid_dataloader:\n",
    "    \n",
    "    z_f, stats = seq_vae.ssm.fast_filter_1_to_T(batch[0], cfg.n_samples)\n",
    "    loss, z, stats = seq_vae.ssm(batch[0], cfg.n_samples)\n",
    "    \n",
    "    z_p = seq_vae.ssm.predict_forward(z_f[:, :, 10], cfg.n_samples)\n",
    "    z_p = torch.cat([z_f[:, :, :10], z_p], dim=2)\n",
    "    \n",
    "    z_f_valid.append(z_f)\n",
    "    z_p_valid.append(z_p)\n",
    "    z_s_valid.append(z)\n",
    "    stats_valid.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c88f0-0e74-4823-ad80-268702942459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9fc735-95e0-4cb2-8fd1-19d3580af316",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = torch.svd(seq_vae.ssm.likelihood_pdf.readout_fn[-1].weight.data)\n",
    "V = S.unsqueeze(-1) * V\n",
    "\n",
    "z_s_train = torch.cat(z_s_train, dim=1)\n",
    "z_s_valid = torch.cat(z_s_valid, dim=1)\n",
    "z_f_valid = torch.cat(z_f_valid, dim=1)\n",
    "z_p_valid = torch.cat(z_p_valid, dim=1)\n",
    "\n",
    "z_s_train = z_s_train[..., :cfg.n_latents_read] @ V\n",
    "z_s_test = z_s_valid[..., :cfg.n_latents_read] @ V\n",
    "z_f_test = z_f_valid[..., :cfg.n_latents_read] @ V\n",
    "z_p_test = z_p_valid[..., :cfg.n_latents_read] @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95850c92-3f85-49e4-a6b0-2af26856a8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"colors\"\"\"\n",
    "blues = cm.get_cmap(\"winter\", z_s_test.shape[0])\n",
    "reds = cm.get_cmap(\"summer\", z_s_test.shape[0])\n",
    "springs = cm.get_cmap(\"spring\", z_s_test.shape[0])\n",
    "\n",
    "color_map_list = [blues, reds, springs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c3e9a-27f1-43e3-923a-0da94000b786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"smoothed\"\"\"\n",
    "with torch.no_grad():\n",
    "\n",
    "    fig, axs = plt.subplots(len(trial_list), 1, figsize=(4, 6))\n",
    "    plot_z_samples(fig, axs, z_s_test[:, trial_list, ..., -3:], color_map_list)\n",
    "    #fig.suptitle('First 3 latents over time, for all neurons, from 4 test trials \\n (smoothing regime) \\n')\n",
    "    fig.suptitle('latents over time (smoothing)')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.annotate('movemebt\\nonset', xy=(12, 0), xytext=(3+12, -30),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "             fontsize=8, ha='center')\n",
    "    \n",
    "    # fig.savefig('plots/z_s_test.png', bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad6526d-fd5a-4a48-bcde-df3d70a58ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"filtered\"\"\"\n",
    "with torch.no_grad():\n",
    "\n",
    "    fig, axs = plt.subplots(len(trial_list), 1, figsize=(4, 6))\n",
    "    plot_z_samples(fig, axs, z_f_test[:, trial_list, ..., -3:], color_map_list)\n",
    "    #fig.suptitle('First 3 latents over time, for all neurons, from 4 test trials \\n(filtering regime) \\n')\n",
    "    fig.suptitle('latents over time (filtering)')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.annotate('movement\\nonset', xy=(12, 0), xytext=(3+12, -30),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "             fontsize=8, ha='center')\n",
    "    \n",
    "    # fig.savefig('plots/z_f_test.png', bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790ff0a-cf52-4e0b-bdcc-8fcc4b86ec4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"predicted\"\"\"\n",
    "with torch.no_grad():\n",
    "\n",
    "    fig, axs = plt.subplots(len(trial_list), 1, figsize=(4, 6))\n",
    "    [axs[i].axvline(10, linestyle='--', color='red') for i in range(len(trial_list))]\n",
    "    plot_z_samples(fig, axs, z_p_test[:, trial_list, ..., -3:], color_map_list)\n",
    "    #fig.suptitle('First 3 latents over time, for all neurons, from 4 test trials \\n(prediction regime) \\n')\n",
    "    fig.suptitle('latents over time')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.annotate('prediction\\nstarts', xy=(10, 0), xytext=(5, -30),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "             fontsize=8, ha='center')\n",
    "    \n",
    "    plt.annotate('movement\\nonset', xy=(12, 0), xytext=(3+12, -30),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "             fontsize=8, ha='center')\n",
    "    \n",
    "    # fig.savefig('plots/z_p_test.png', bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9457253-bd3b-45a8-b2e1-794a173b9158",
   "metadata": {},
   "source": [
    "# Evaluating Model Performance\n",
    "The most trivial way to start with is just to plot the training and validation losses. Good we have the logs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee6924-8e7a-4179-88f0-ae382e1e6d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading the logs\n",
    "\n",
    "logs_path = 'logs/smoother/acausal/sd_1236_r_y_15_r_b_5/smoother_acausal/metrics.csv'\n",
    "metrics = pd.read_csv(logs_path).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f60980-35b9-4533-b21e-f5be99543c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f297fb-6086-4f66-bb4e-329e942aadc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(\n",
    "    metrics['train_loss'].keys(),\n",
    "    metrics['train_loss'].values(),\n",
    "    marker='o', markersize=2, linestyle='-', color='g', alpha=0.6, linewidth=1, label='train')\n",
    "\n",
    "plt.plot(\n",
    "    metrics['valid_loss'].keys(),\n",
    "    metrics['valid_loss'].values(),\n",
    "    marker='o', markersize=2, linestyle='-', color='y', alpha=0.6, linewidth=1, label='valid')\n",
    "\n",
    "# plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (ELBO)')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# plt.savefig('plots/loss.png', bbox_inches='tight', transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6011f-24da-46bf-851b-dc2c4b7527b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "with torch.no_grad():\n",
    "    plt.plot(\n",
    "        stats['kl'][286],\n",
    "        marker='o', markersize=2, linestyle='-', alpha=0.6, linewidth=1)\n",
    "\n",
    "plt.xlabel('time bins')\n",
    "plt.ylabel('KL')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb7239-b85f-4175-8758-9b270869121f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(\n",
    "    list(metrics['r2_train_enc'].keys())[1:],\n",
    "    list(metrics['r2_train_enc'].values())[1:],\n",
    "    marker='o', markersize=2, linestyle='-', color='g', alpha=0.6, linewidth=1, label='train')\n",
    "\n",
    "plt.plot(\n",
    "    list(metrics['r2_valid_enc'].keys())[1:],\n",
    "    list(metrics['r2_valid_enc'].values())[1:],\n",
    "    marker='o', markersize=2, linestyle='-', color='y', alpha=0.6, linewidth=1, label='valid')\n",
    "\n",
    "#plt.title('R2')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('r2')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# plt.savefig('plots/r2.png', bbox_inches='tight', transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77ed02-ae7a-4bd2-9ea7-a6c92282888f",
   "metadata": {},
   "source": [
    "Another way to evaluate model performance is the **Bits per Spike (BpS)**. Which is a quantification of how neurons encode information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a884d1-603a-4456-a798-88e36c20b400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(\n",
    "    metrics['train_bps_enc'].keys(),\n",
    "    metrics['train_bps_enc'].values(),\n",
    "    marker='o', markersize=2, linestyle='-', color='g', alpha=0.6, linewidth=1, label='train')\n",
    "\n",
    "plt.plot(\n",
    "    metrics['valid_bps_enc'].keys(),\n",
    "    metrics['valid_bps_enc'].values(),\n",
    "    marker='o', markersize=2, linestyle='-', color='y', alpha=0.6, linewidth=1, label='valid')\n",
    "\n",
    "# plt.title('Bits per Spike for Training and Validation')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('bits per spike')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# plt.savefig('plots/bps.png', bbox_inches='tight', transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cac625-c865-4388-a366-ee333247a8b3",
   "metadata": {},
   "source": [
    "The previous plots were all about the evolution of the model performance throughout training (loss x epochs). Aonther way to evaluate how the model captures the tuning properties of neurons relative to the stimulus over time is to look at the **peri-stimulus time histogram (PSTH)**.\n",
    "\n",
    "We will generate condition averaged (in our example, conditions are the reaching directions) PSTHs from the model and compare them to the condition averaged PSTHs from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee934b-33b8-495e-a77e-93edf3d51502",
   "metadata": {},
   "source": [
    "# Breaking down the state space model learned by XFADS\n",
    "\n",
    "One of the main functionalities of XFADS is breaking the amortized inference step into two additive components: the `local_encoder` and the `backward_encoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65faac27-a511-4c1e-85bd-ddf3a37f848c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"extract trained ssm from lightning module\"\"\"\n",
    "seq_vae.ssm = seq_vae.ssm.to(cfg.device)\n",
    "seq_vae.ssm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0eccf1-ae59-4c72-bb2d-7acf93a736dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    trial_idx = np.random.randint(0, n_valid_trials)\n",
    "    \n",
    "    n_trajectories_to_plot = 9\n",
    "    n_latents_to_plot = 3\n",
    "\n",
    "    fig, axes = plt.subplots(int(np.sqrt(n_trajectories_to_plot)), int(np.sqrt(n_trajectories_to_plot)), figsize=(10, 8), subplot_kw={'projection': '3d'})\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f'latent trajectories from trial {trial_idx+1}\\n\\n\\n\\n')\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        \n",
    "        latent1, latent2, latent3 = np.random.choice(range(0, cfg.n_latents_read), size=n_latents_to_plot, replace=False)\n",
    "        \n",
    "        # Select three latent dimensions for 3D plotting\n",
    "        x = torch.tensor(gaussian_filter1d(torch.mean(z_s_test[:, trial_idx, ..., latent1], dim=0), sigma=4, axis=0))\n",
    "        y = torch.tensor(gaussian_filter1d(torch.mean(z_s_test[:, trial_idx, ..., latent2], dim=0), sigma=4, axis=0))\n",
    "        z = torch.tensor(gaussian_filter1d(torch.mean(z_s_test[:, trial_idx, ..., latent3], dim=0), sigma=4, axis=0))\n",
    "\n",
    "        ax.plot(x, y, z, label='smoothed' if i == 0 else '')\n",
    "        \n",
    "        x_p = torch.tensor(gaussian_filter1d(torch.mean(z_p_test[:, trial_idx, ..., latent1], dim=0), sigma=4, axis=0))\n",
    "        y_p = torch.tensor(gaussian_filter1d(torch.mean(z_p_test[:, trial_idx, ..., latent2], dim=0), sigma=4, axis=0))\n",
    "        z_p = torch.tensor(gaussian_filter1d(torch.mean(z_p_test[:, trial_idx, ..., latent3], dim=0), sigma=4, axis=0))\n",
    "        \n",
    "        ax.tick_params(axis='x', labelsize=6)\n",
    "        ax.tick_params(axis='y', labelsize=6)\n",
    "        ax.tick_params(axis='z', labelsize=6)\n",
    "        \n",
    "        ax.plot(x_p, y_p, z_p, label='predicted' if i == 0 else '')\n",
    "        \n",
    "        ax.set_title(f'latents {latent1+1}, {latent2+1}, {latent3+1}', fontsize=8)\n",
    "        #ax.set_xlabel(f'latent {latent1}', fontsize=8)\n",
    "        #ax.set_ylabel(f'latent {latent2}', fontsize=8)\n",
    "        #ax.set_zlabel(f'latent {latent3}', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.6)\n",
    "    \n",
    "    fig.legend(loc='upper center', bbox_to_anchor=(0.5, 0.94), ncol=1, fontsize=7)\n",
    "\n",
    "    # fig.savefig('plots/3d_trajectory.png', bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f8b3b6-2961-4cfa-b801-41dcfdffd007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 5), subplot_kw={'projection': '3d'})\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    n_latents_to_plot = 3\n",
    "    n_trajectories_to_plot = 3\n",
    "    \n",
    "    trial_idx = np.random.randint(0, z_s_test.shape[1])\n",
    "    \n",
    "    for i in range(n_trajectories_to_plot):\n",
    "        \n",
    "        # Any random 3 latents\n",
    "        latent1, latent2, latent3 = np.random.choice(range(0, cfg.n_latents_read), size=n_latents_to_plot, replace=False)\n",
    "\n",
    "        # Select three latent dimensions for 3D plotting\n",
    "        x = torch.tensor(\n",
    "            gaussian_filter1d(\n",
    "                torch.mean(\n",
    "                    z_s_test[:, trial_idx, ..., latent1], dim=0), sigma=4, axis=0))\n",
    "        \n",
    "        y = torch.tensor(\n",
    "            gaussian_filter1d(\n",
    "                torch.mean(\n",
    "                    z_s_test[:, trial_idx, ..., latent2], dim=0), sigma=4, axis=0))\n",
    "        \n",
    "        z = torch.tensor(\n",
    "            gaussian_filter1d(\n",
    "                torch.mean(\n",
    "                    z_s_test[:, trial_idx, ..., latent3], dim=0), sigma=4, axis=0))\n",
    "\n",
    "        ax.plot(x, y, z, label=f'latents {latent1+1}, {latent2+1}, {latent3+1}')\n",
    "        \n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    fig.suptitle(f'trial {trial_idx+1}')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # fig.savefig('plots/3d_trajectory_in_one_fig.png', bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c44bb4-b118-40e3-be84-ce5d62760a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 5), subplot_kw={'projection': '3d'})\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    n_latents_to_plot = 3\n",
    "    n_trajectories_to_plot = 5\n",
    "    \n",
    "    trials_inds = np.random.choice(range(0, y_valid_obs.shape[0]), size=n_trajectories_to_plot, replace=False)\n",
    "    \n",
    "    # top 3 latents (not indices)\n",
    "    latent1, latent2, latent3 = [0, 1, 2]\n",
    "    \n",
    "    for i in range(n_trajectories_to_plot):\n",
    "\n",
    "        # Select three latent dimensions for 3D plotting\n",
    "        x = torch.tensor(\n",
    "            gaussian_filter1d(\n",
    "                torch.mean(\n",
    "                    z_s_test[:, trials_inds[i], ..., latent1], dim=0), sigma=4, axis=0))\n",
    "        \n",
    "        y = torch.tensor(\n",
    "            gaussian_filter1d(\n",
    "                torch.mean(\n",
    "                    z_s_test[:, trials_inds[i], ..., latent2], dim=0), sigma=4, axis=0))\n",
    "        \n",
    "        z = torch.tensor(\n",
    "            gaussian_filter1d(\n",
    "                torch.mean(\n",
    "                    z_s_test[:, trials_inds[i], ..., latent3], dim=0), sigma=4, axis=0))\n",
    "\n",
    "        ax.plot(x, y, z, label=f'trial {trials_inds[i]+1}')\n",
    "        \n",
    "    ax.legend(fontsize=8)\n",
    "    ax.view_init(elev=20., azim=-35)\n",
    "    ax.set_xlabel('1st latent')\n",
    "    ax.set_ylabel('2nd latent')\n",
    "    ax.set_zlabel('3rd latent')\n",
    "    \n",
    "    fig.suptitle(f'top 3 latents')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # fig.savefig('plots/3d_trajectory_in_test_trials.png', bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7830851-0e64-4134-ba73-bc5f73d408bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    fig, axs = plt.subplots(len(trial_list), 1, figsize=(4, 8))\n",
    "    default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    \n",
    "    plot_z_2d(fig, axs, trial_list, z_f_test[:, trial_list, ..., :3], color=default_colors[0], regime='filtered')\n",
    "    plot_z_2d(fig, axs, trial_list, z_p_test[:, trial_list, ..., :3], color=default_colors[1], regime='predicted')\n",
    "    \n",
    "    #fig.suptitle('First 3 latents over time, for all neurons, from 4 test trials \\n (smoothing regime) \\n')\n",
    "    fig.suptitle('filtered vs predicted\\n\\n\\n\\n')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.annotate('prediction\\nstarts', xy=(10, 0), xytext=(5, -15),\n",
    "             arrowprops=dict(facecolor='gray', arrowstyle='->', alpha=0.5),\n",
    "             fontsize=8, ha='center')\n",
    "    \n",
    "    plt.annotate('movement\\nonset', xy=(12, 0), xytext=(3+12, -15),\n",
    "             arrowprops=dict(facecolor='gray', arrowstyle='->', alpha=0.5),\n",
    "             fontsize=8, ha='center')\n",
    "    \n",
    "    fig.legend(loc='upper center', bbox_to_anchor=(0.47, 0.94), shadow=True, ncol=1, fontsize=6)\n",
    "    \n",
    "    # fig.savefig('plots/f_vs_p.png', bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d5c16a-24e8-4d5f-814f-39a51c360bb9",
   "metadata": {},
   "source": [
    "# Generating corresponding observations\n",
    "We can use the likelifood function (observation model) to generate new data (log rates) from the latents. And sampele from the rates possion to get the spike counts.\n",
    "\n",
    "Data dimentionality:\\\n",
    "**generated** : sampels x trials x time bins x neurons\\\n",
    "sampels = samples of the latents each of which used to generate the data\\\n",
    "**real**: trials x time bins x neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b12ff9-c7e1-4fc6-ad01-683bd90b3c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# smoothed and predicted log rates\n",
    "r_s = seq_vae.ssm.to(cfg.data_device).likelihood_pdf.readout_fn(z_s_test)\n",
    "r_p = seq_vae.ssm.to(cfg.data_device).likelihood_pdf.readout_fn(z_p_test)\n",
    "# sampeling from the rates possion to get the spike counts\n",
    "y_s = torch.poisson(cfg.bin_sz * torch.exp(r_s))\n",
    "y_p = torch.poisson(cfg.bin_sz * torch.exp(r_p))\n",
    "\n",
    "y_hat = torch.cat([y_s[:, :, :n_bins_bhv], y_p], dim=2)\n",
    "z_hat = torch.cat([z_s_test[:, :, :n_bins_bhv, :], z_p_test], dim=2)\n",
    "i = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f24cf9-8484-4f81-ae45-c47a79605c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    trial_idx = np.random.randint(0, y_test_obs.shape[1])\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(4, 6))\n",
    "    plot_spikes(y_test_obs[trial_idx], axs[0])\n",
    "    plot_spikes(y_hat[0, trial_idx], axs[1])\n",
    "\n",
    "    fig.suptitle(f'trial {trial_idx}\\n(active neurons ordered by their spikes count)', fontsize=10)\n",
    "    \n",
    "    # fig.savefig('plots/generated_spikes.svg', bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41651780-26c3-4d18-b601-e56bb9d6764a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " with torch.no_grad():\n",
    "        \n",
    "    neuron_idx = np.random.randint(0, n_neurons_obs)\n",
    "    \n",
    "    y = torch.tensor(gaussian_filter1d(torch.mean(torch.exp(r_s)[0, :, :, neuron_idx], axis=0), sigma=2.5, axis=0))\n",
    "    \n",
    "    plt.plot(np.arange(n_time_bins) * cfg.bin_sz_ms, y)\n",
    "    \n",
    "    plt.title(f'trial-averaged inferred firing rate of neuron {neuron_idx+1}\\n')\n",
    "    plt.xlabel('time (sec)')\n",
    "    plt.ylabel('firing rate')\n",
    "    plt.axvline(x=move_onset*cfg.bin_sz_ms, color='r', linestyle='--')\n",
    "    plt.annotate('movement\\nonset', xy=(move_onset*cfg.bin_sz_ms, torch.min(y)), xytext=((move_onset*cfg.bin_sz_ms)*0.6, torch.min(y)+(torch.max(y)-torch.min(y))*0.05),\n",
    "                     arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "                     fontsize=8, ha='center')\n",
    "    \n",
    "    # plt.savefig('plots/r_s.png')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3f3cfd-b70c-4bfe-b17f-d1d7a91c807a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trials_inds = np.random.choice(range(0, y_valid_obs.shape[0]), size=n_trajectories_to_plot, replace=False)\n",
    "\n",
    "plot_rastor(y_valid_obs, z_s_test, trials_inds, y_valid_obs.shape[2])\n",
    "plot_rastor(y_hat[0], z_s_test, trials_inds, y_hat.shape[3], regime='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f7527-2974-4db8-be46-27ec327996fa",
   "metadata": {},
   "source": [
    "## Ordering the neurons in terms of their loading to the 1st principal latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91935f70-c816-4ee1-b96d-1e27e584a409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial_idx = np.random.randint(0, y_valid_obs.shape[0])\n",
    "ordered_correlations, ordered_neurons = order_neurons(y_valid_obs, z_s_test, trial=trial_idx, latent=0)\n",
    "\n",
    "top_n = 10\n",
    "\n",
    "time_bins = [str(i) for i in ordered_neurons[:top_n].astype('int32')]\n",
    "\n",
    "y = np.abs(ordered_correlations.T[1][:top_n])\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "axes.plot(time_bins, y, marker='o', linestyle='-', color='g')\n",
    "\n",
    "for i in range(len(time_bins)):\n",
    "    plt.text(time_bins[i], y[i]+0.005, f'{y[i]:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    plt.vlines(i, ymin=y.min(), ymax=y[i], linestyles='dashed', colors='gray', alpha=0.5)\n",
    "\n",
    "fig.suptitle(f'top 10 neurons in trial {trial_idx+1} ordered based on their loading\\nto the 1st principal latent dimension\\n\\n\\n\\n')\n",
    "plt.ylim(top=y.max()+0.05*y.max())\n",
    "\n",
    "plt.xlabel('top 10 neurons')\n",
    "plt.ylabel('correlation')\n",
    "\n",
    "# fig.savefig('plots/corrcoef(averaged_samples).png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599b55d-24c7-4795-994b-26f9965252b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trials_inds = np.random.choice(range(0, y_valid_obs.shape[0]), size=n_trajectories_to_plot, replace=False)\n",
    "\n",
    "plot_rastor(y_valid_obs, z_s_test, trials_inds, y_valid_obs.shape[2], order=True)\n",
    "plot_rastor(y_hat[0], z_s_test, trials_inds, y_hat.shape[3], regime='prediction', order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcef989-5585-45fd-be2f-6d03abfdc84f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spike_count = torch.sum(y_valid_obs, axis=1)\n",
    "\n",
    "plt.imshow(spike_count, interpolation='nearest', aspect=0.9)\n",
    "plt.colorbar()\n",
    "plt.title('spike counts\\n')\n",
    "plt.xlabel('neurons')\n",
    "plt.ylabel('trials')\n",
    "\n",
    "# plt.savefig('silent_vs_active_neurons.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1a15b-6601-4e40-93f4-c63a19d3a3bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fn\n",
    "import pytorch_lightning as lightning\n",
    "\n",
    "from pyrecorder.recorder import Recorder\n",
    "from pyrecorder.writers.video import Video\n",
    "from pyrecorder.converters.matplotlib import Matplotlib\n",
    "\n",
    "import xfads.utils as utils\n",
    "import xfads.prob_utils as prob_utils\n",
    "from xfads import plot_utils\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from xfads.ssm_modules.likelihoods import PoissonLikelihood\n",
    "from xfads.ssm_modules.dynamics import DenseGaussianDynamics\n",
    "from xfads.ssm_modules.dynamics import DenseGaussianInitialCondition\n",
    "from xfads.ssm_modules.encoders import LocalEncoderLRMvn, BackwardEncoderLRMvn\n",
    "from xfads.smoothers.lightning_trainers import LightningNonlinearSSM, LightningMonkeyReaching\n",
    "from xfads.smoothers.nonlinear_smoother_causal import NonlinearFilter, LowRankNonlinearStateSpaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2371e85e-9a8b-40bc-b6d2-7e4015987eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_trials_plot = 125\n",
    "n_samples_mu_plt = 20\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=\"\", job_name=\"monkey_reaching\")\n",
    "cfg = compose(config_name=\"config\")\n",
    "cfg.data_device = 'cpu'\n",
    "cfg.device = 'cpu'\n",
    "\n",
    "lightning.seed_everything(cfg.seed, workers=True)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ece5766-87c4-4687-a0ed-e924850168ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"data\"\"\"\n",
    "data_path = 'data/data_{split}_{bin_sz_ms}ms.pt'\n",
    "train_data = torch.load(data_path.format(split='train', bin_sz_ms=cfg.bin_sz_ms))\n",
    "val_data = torch.load(data_path.format(split='test', bin_sz_ms=cfg.bin_sz_ms))\n",
    "test_data = torch.load(data_path.format(split='test', bin_sz_ms=cfg.bin_sz_ms))\n",
    "\n",
    "y_valid_obs = val_data['y_obs'].type(torch.float32).to(cfg.data_device)[:, :35]\n",
    "y_train_obs = train_data['y_obs'].type(torch.float32).to(cfg.data_device)[:, :35]\n",
    "y_test_obs = test_data['y_obs'].type(torch.float32).to(cfg.data_device)[:, :35]\n",
    "vel_valid = val_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_train = train_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_test = test_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "n_trials, n_time_bins, n_neurons_obs = y_train_obs.shape\n",
    "n_time_bins_enc = train_data['n_time_bins_enc']\n",
    "batch_sz_test = list(y_test_obs.shape)[:-1]\n",
    "n_trials_test = y_test_obs.shape[0]\n",
    "\n",
    "y_train_dataset = torch.utils.data.TensorDataset(y_train_obs, vel_train)\n",
    "y_val_dataset = torch.utils.data.TensorDataset(y_valid_obs, vel_valid)\n",
    "y_test_dataset = torch.utils.data.TensorDataset(y_test_obs, vel_test)\n",
    "train_dataloader = torch.utils.data.DataLoader(y_train_dataset, batch_size=cfg.batch_sz, shuffle=False)\n",
    "valid_dataloader = torch.utils.data.DataLoader(y_val_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(y_test_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f3127-8c27-4b2e-b2c9-73eb8cf7c2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"likelihood pdf\"\"\"\n",
    "H = utils.ReadoutLatentMask(cfg.n_latents, cfg.n_latents_read)\n",
    "readout_fn = nn.Sequential(H, nn.Linear(cfg.n_latents_read, n_neurons_obs))\n",
    "readout_fn[-1].bias.data = prob_utils.estimate_poisson_rate_bias(train_dataloader, cfg.bin_sz)\n",
    "likelihood_pdf = PoissonLikelihood(readout_fn, n_neurons_obs, cfg.bin_sz, device=cfg.device)\n",
    "\n",
    "\"\"\"dynamics module\"\"\"\n",
    "Q_diag = 1. * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "dynamics_fn = utils.build_gru_dynamics_function(cfg.n_latents, cfg.n_hidden_dynamics, device=cfg.device)\n",
    "dynamics_mod = DenseGaussianDynamics(dynamics_fn, cfg.n_latents, Q_diag, device=cfg.device)\n",
    "\n",
    "\"\"\"initial condition\"\"\"\n",
    "m_0 = torch.zeros(cfg.n_latents, device=cfg.device)\n",
    "Q_0_diag = 1. * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "initial_condition_pdf = DenseGaussianInitialCondition(cfg.n_latents, m_0, Q_0_diag, device=cfg.device)\n",
    "\n",
    "\"\"\"local/backward encoder\"\"\"\n",
    "backward_encoder = BackwardEncoderLRMvn(cfg.n_latents, cfg.n_hidden_backward, cfg.n_latents,\n",
    "                                        rank_local=cfg.rank_local, rank_backward=cfg.rank_backward,\n",
    "                                        device=cfg.device)\n",
    "local_encoder = LocalEncoderLRMvn(cfg.n_latents, n_neurons_obs, cfg.n_hidden_local, cfg.n_latents,\n",
    "                                  rank=cfg.rank_local,\n",
    "                                  device=cfg.device, dropout=cfg.p_local_dropout)\n",
    "nl_filter = NonlinearFilter(dynamics_mod, initial_condition_pdf, device=cfg.device)\n",
    "\n",
    "\"\"\"sequence vae\"\"\"\n",
    "ssm = LowRankNonlinearStateSpaceModel(dynamics_mod, likelihood_pdf, initial_condition_pdf, backward_encoder,\n",
    "                                      local_encoder, nl_filter, device=cfg.device)\n",
    "\n",
    "\"\"\"lightning\"\"\"\n",
    "best_model_path = 'ckpts/smoother/acausal/epoch=692_valid_loss=1415.51_r2_valid_enc=0.89_r2_valid_bhv=0.73_valid_bps_enc=0.41.ckpt'\n",
    "seq_vae = LightningMonkeyReaching.load_from_checkpoint(best_model_path, ssm=ssm, cfg=cfg,\n",
    "                                                       n_time_bins_enc=n_time_bins_enc, n_time_bins_bhv=cfg.n_bins_bhv,\n",
    "                                                       strict=False)\n",
    "seq_vae.ssm = seq_vae.ssm.to(cfg.device)\n",
    "seq_vae.ssm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40141620-5273-451a-acee-ab5ef713f418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"inference\"\"\"\n",
    "z_s_train = []\n",
    "\n",
    "z_s_test = []\n",
    "z_f_test = []\n",
    "z_p_test = []\n",
    "\n",
    "z_s_valid = []\n",
    "z_f_valid = []\n",
    "z_p_valid = []\n",
    "\n",
    "m_0 = seq_vae.ssm.nl_filter.initial_c_pdf.m_0\n",
    "Q_0 = Fn.softplus(seq_vae.ssm.nl_filter.initial_c_pdf.log_Q_0)\n",
    "#m_0 = seq_vae.ssm.dynamics_mod.initial_c_pdf.m_0\n",
    "#Q_0 = Fn.softplus(seq_vae.ssm.dynamics_mod.initial_c_pdf.log_Q_0)\n",
    "\n",
    "z_ic = m_0 + Q_0.sqrt() * torch.randn(batch_sz_test + [cfg.n_latents], device=cfg.device)\n",
    "z_ic_p = seq_vae.ssm.predict_forward(z_ic, 35 - cfg.n_bins_bhv)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    loss, z, stats = seq_vae.ssm(batch[0], cfg.n_samples)\n",
    "    z_s_train.append(z)\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    z_f, stats = seq_vae.ssm.fast_filter_1_to_T(batch[0], cfg.n_samples)\n",
    "    loss, z, stats = seq_vae.ssm(batch[0], cfg.n_samples)\n",
    "    z_p = seq_vae.ssm.predict_forward(z_f[:, :, cfg.n_bins_bhv], 35-cfg.n_bins_bhv)\n",
    "    z_p = torch.cat([z_f[:, :, :cfg.n_bins_bhv], z_p], dim=2)\n",
    "    z_f_test.append(z_f)\n",
    "    z_p_test.append(z_p)\n",
    "    z_s_test.append(z)\n",
    "    \n",
    "for batch in valid_dataloader:\n",
    "    z_f, stats = seq_vae.ssm.fast_filter_1_to_T(batch[0], cfg.n_samples)\n",
    "    loss, z, stats = seq_vae.ssm(batch[0], cfg.n_samples)\n",
    "    z_p = seq_vae.ssm.predict_forward(z_f[:, :, cfg.n_bins_bhv], cfg.n_samples)\n",
    "    z_p = torch.cat([z_f[:, :, :10], z_p], dim=2)\n",
    "    z_f_valid.append(z_f)\n",
    "    z_p_valid.append(z_p)\n",
    "    z_s_valid.append(z)\n",
    "\n",
    "z_s_train = torch.cat(z_s_train, dim=1)\n",
    "\n",
    "z_s_test = torch.cat(z_s_test, dim=1)\n",
    "z_f_test = torch.cat(z_f_test, dim=1)\n",
    "z_p_test = torch.cat(z_p_test, dim=1)\n",
    "\n",
    "z_s_valid = torch.cat(z_s_valid, dim=1)\n",
    "z_f_valid = torch.cat(z_f_valid, dim=1)\n",
    "z_p_valid = torch.cat(z_p_valid, dim=1)\n",
    "\n",
    "rates_train_s = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_s_train)).mean(dim=0)\n",
    "\n",
    "rates_test_s = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_s_test)).mean(dim=0)\n",
    "rates_test_f = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_f_test)).mean(dim=0)\n",
    "rates_test_p = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_p_test)).mean(dim=0)\n",
    "\n",
    "rates_valid_s = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_s_valid)).mean(dim=0)\n",
    "rates_valid_f = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_f_valid)).mean(dim=0)\n",
    "rates_valid_p = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_p_valid)).mean(dim=0)\n",
    "\n",
    "#rates = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_s_train)).mean(dim=0)\n",
    "#rates_test = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_s_valid)).mean(dim=0)\n",
    "#rates_filter = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_f_valid)).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d4e9d-6c3b-497a-ac84-48f3cae45872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"velocity decoder\"\"\"\n",
    "with torch.no_grad():\n",
    "    clf = Ridge(alpha=0.01)\n",
    "    # fit to training data\n",
    "    clf.fit(rates_train_s.reshape(-1, n_neurons_obs), vel_train.reshape(-1, 2))\n",
    "    r2 = clf.score(rates_train_s.reshape(-1, n_neurons_obs), vel_train.reshape(-1, 2))\n",
    "    r2_test = clf.score(rates_test_s.reshape(-1, n_neurons_obs), vel_valid.reshape(-1, 2))\n",
    "    r2_filter = clf.score(rates_test_f.reshape(-1, n_neurons_obs), vel_valid.reshape(-1, 2))\n",
    "    r2_k_step = []\n",
    "\n",
    "    # transform test data\n",
    "    r2_test_s = clf.score(rates_test_s.reshape(-1, n_neurons_obs), vel_test.reshape(-1, 2))\n",
    "    r2_test_f = clf.score(rates_test_f.reshape(-1, n_neurons_obs), vel_test.reshape(-1, 2))\n",
    "    r2_test_p = clf.score(rates_test_p.reshape(-1, n_neurons_obs), vel_test.reshape(-1, 2))\n",
    "    vel_hat_test_s = clf.predict(rates_test_s.reshape(-1, n_neurons_obs)).reshape(list(batch_sz_test) + [2])\n",
    "    vel_hat_test_f = clf.predict(rates_test_f.reshape(-1, n_neurons_obs)).reshape(list(batch_sz_test) + [2])\n",
    "    vel_hat_test_p = clf.predict(rates_test_p.reshape(-1, n_neurons_obs)).reshape(list(batch_sz_test) + [2])\n",
    "    \n",
    "    for k in range(30):\n",
    "        z_prd_test = utils.propagate_latent_k_steps(z_f_valid[:, :, k], dynamics_mod, n_time_bins + 0 - (k + 1))\n",
    "        z_prd_test = torch.concat([z_f_valid[:, :, :k], z_prd_test], dim=2)\n",
    "\n",
    "        # m_prd_test = z_prd_test.mean(dim=0)\n",
    "        # m_prd_test = torch.concat([m_filter[:, :k], m_prd_test[:, k:]], dim=1)\n",
    "\n",
    "        rates_prd_test = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_prd_test)).mean(dim=0)\n",
    "\n",
    "        r2_prd = clf.score(rates_prd_test.reshape(-1, n_neurons_obs), vel_valid.reshape(-1, 2))\n",
    "        r2_k_step.append(r2_prd)\n",
    "\n",
    "    vel_to_pos = lambda v: torch.cumsum(torch.tensor(v), dim=1)\n",
    "\n",
    "    pos_test = vel_to_pos(vel_test)\n",
    "    pos_test_hat_s = vel_to_pos(vel_hat_test_s)\n",
    "    pos_test_hat_f = vel_to_pos(vel_hat_test_f)\n",
    "    pos_test_hat_p = vel_to_pos(vel_hat_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2a4da-26df-456a-ad56-78f8c1d2f704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"plotting\"\"\"\n",
    "blues = cm.get_cmap(\"Blues\", n_samples_mu_plt)\n",
    "grays = cm.get_cmap(\"Greys\", n_samples_mu_plt)\n",
    "yellows = cm.get_cmap(\"YlOrBr\", n_samples_mu_plt)\n",
    "\n",
    "trial_plt_dx = torch.randperm(n_trials_test)[:n_trials_plot]\n",
    "reach_angle = torch.atan2(pos_test[:, -1, 0], pos_test[:, -1, 1])\n",
    "reach_colors = plt.cm.hsv(reach_angle / (2 * np.pi) + 0.5)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
    "\n",
    "    plot_utils.plot_reaching(axs[0], pos_test[trial_plt_dx], reach_colors[trial_plt_dx])\n",
    "    plot_utils.plot_reaching(axs[1], pos_test_hat_s[trial_plt_dx], reach_colors[trial_plt_dx])\n",
    "    plot_utils.plot_reaching(axs[2], pos_test_hat_f[trial_plt_dx], reach_colors[trial_plt_dx])\n",
    "    plot_utils.plot_reaching(axs[3], pos_test_hat_p[trial_plt_dx], reach_colors[trial_plt_dx])\n",
    "\n",
    "    axs[0].set_title('true')\n",
    "    axs[1].set_title(f'smoothed, r2:{r2_test_s:.3f}')\n",
    "    axs[2].set_title(f'filtered, r2:{r2_test_f:.3f}')\n",
    "    axs[3].set_title(f'predicted, r2:{r2_test_p:.3f}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5834cf-6726-42c5-b734-ed367e41bbe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.axvline(12, linestyle='--')\n",
    "plt.plot(r2_k_step)\n",
    "plt.axhline(r2_test, color='green', label='smoothed')\n",
    "plt.axhline(r2_filter, color='orange', label='filtered')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c029b-2e75-4de2-8825-6f9ccc96bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_train_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e353b-0bec-4170-b676-d6642a626fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vel_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19858eb1-88f0-4e5a-8839-3104184e6881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_s_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbaf728-4d63-4c11-85da-931641f87d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfads",
   "language": "python",
   "name": "xfads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
