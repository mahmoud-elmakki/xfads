{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b81c5c88-d8c2-4b4f-a0ae-30038e78cdb3",
   "metadata": {},
   "source": [
    "# eXponential Family Dynamical Systems (XFADS): Large-scale nonlinear Gaussian state-space modeling\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/catniplab/xfads/blob/workshop/workshop/monkey_reaching/main.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "<br>Approximate inference targeted at variational Gaussian state-space models with dense covariance matrix approximations.  For more details, see our paper: [Dowling, Zhao, Park. 2024](https://arxiv.org/abs/2403.01371)\n",
    "\n",
    "This is a walk-through for the minimal functioning of XFADS. We will be building a toy model on the [MC_Maze](https://neurallatents.github.io/datasets.html) dataset as a benchmark, which is a delayed center-out reaching task with barriers.<br>\n",
    "With the adequate configs, you can fit XFADS on different spans of neural data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deffa431-270b-422a-83c1-12f08cb7d251",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Installation\n",
    "After cloning the repo, and installing anaconda, or miniconda, create the environment by running:<br>\n",
    "`conda env create -f environment.yaml`<br>\n",
    "\n",
    "Add the `xfads` package to the `PYTHONPATH` of the environment<br>\n",
    "`pip install -e .`<br>\n",
    "\n",
    "If you are on Google Colab, which is recommended (just make sure to zip and download the trained models), run the following cell to clone the repo and install the requirements, and you are ready to go!<br>\n",
    "(Since Colab uses sessions anyway, it won't be that useful to use an environment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b2c00-a9e2-4cd3-b553-fcfd05cae763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_running_in_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "if is_running_in_colab():\n",
    "    !git clone https://github.com/catniplab/xfads.git\n",
    "    %cd xfads\n",
    "    # install the dependencies\n",
    "    !pip install torch pytorch-lightning scikit-learn hydra-core matplotlib einops\n",
    "    # wrap the XFADS package\n",
    "    !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6276424f-2488-4214-8c83-9e2826657ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import hydra\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as lightning\n",
    "\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from mc_utils import *\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from xfads import plot_utils\n",
    "from xfads.smoothers.lightning_trainers import LightningMonkeyReaching\n",
    "from xfads.ssm_modules.prebuilt_models import create_xfads_poisson_log_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ae4e6-c0d2-41ae-838c-e84ad0aae6bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c55abd-d3bb-4692-ad46-d1a40918d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=\"\", job_name=\"monkey_reaching\")\n",
    "\n",
    "cfg = compose(config_name=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e19a4a-7edb-4b85-a8bb-314d35836deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning.seed_everything(cfg.seed, workers=True)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f923cdc-62c6-4bbb-916b-bdf4f7d1690d",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "Here we are using the [MC_Maze:](https://dandiarchive.org/dandiset/000128?search=mc_maze&pos=4) macaque primary motor and dorsal premotor cortex spiking activity during delayed reaching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545301b5-38ad-40de-aea4-b7318414e8a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! dandi download DANDI:000128/0.220113.0400 --output-dir ./data\n",
    "%run download_data_from_nwb.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942e4f1-d781-4332-aced-53464f768240",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/data_{split}_{bin_sz_ms}ms.pt'\n",
    "train_data = torch.load(data_path.format(split='train', bin_sz_ms=cfg.bin_sz_ms))\n",
    "val_data = torch.load(data_path.format(split='valid', bin_sz_ms=cfg.bin_sz_ms))\n",
    "test_data = torch.load(data_path.format(split='test', bin_sz_ms=cfg.bin_sz_ms))\n",
    "\n",
    "y_train_obs = train_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "y_valid_obs = val_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "y_test_obs = test_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "\n",
    "vel_train = train_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_valid = val_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_test = test_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "\n",
    "y_train_dataset = torch.utils.data.TensorDataset(y_train_obs, vel_train)\n",
    "y_val_dataset = torch.utils.data.TensorDataset(y_valid_obs, vel_valid)\n",
    "y_test_dataset = torch.utils.data.TensorDataset(y_test_obs, vel_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(y_train_dataset, batch_size=cfg.batch_sz, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(y_val_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(y_test_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)\n",
    "\n",
    "# Data dimensions\n",
    "n_train_trials, n_time_bins, n_neurons_obs = y_train_obs.shape\n",
    "n_valid_trials = y_valid_obs.shape[0]\n",
    "n_test_trials = y_test_obs.shape[0]\n",
    "n_time_bins_enc = train_data['n_time_bins_enc']\n",
    "\n",
    "print(\"# training trials: {0}\".format(n_train_trials))\n",
    "print(\"# validation trials: {0}\".format(n_valid_trials))\n",
    "print(\"# testing trials: {0}\".format(n_test_trials))\n",
    "print(\"# neurons: {0}\".format(n_neurons_obs))\n",
    "print(\"# time bins: {0}\".format(n_time_bins))\n",
    "print(\"# time bins used for forcasting: {0}\".format(cfg.n_bins_bhv))\n",
    "print(\"# predicted time bins: {0}\".format(n_time_bins - cfg.n_bins_bhv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3705019-2737-4f80-aa0a-270bfecfd9d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Structuring the State-Space Model\n",
    "\n",
    "The configuration depends on the problem - `dynamics_mod`, `initial_c_pdf`, `likelihood_pdf`, `local_encoder`, and `backward_encoder` can be configured as desired. We include some general classes in `ssm_modules/encoders`, `ssm_modules/likelihoods` and `ssm_modules/dynamics` that should be sufficient for a wide range of problems.  Below is an example configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01082bb9-e57d-4a8c-a134-e0eba4946d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"create ssm\"\"\"\n",
    "ssm = create_xfads_poisson_log_link(cfg, n_neurons_obs, train_dataloader, model_type='n')\n",
    "\n",
    "\"\"\"lightning\"\"\"\n",
    "seq_vae = LightningMonkeyReaching(ssm, cfg, n_time_bins_enc, cfg.n_bins_bhv)\n",
    "csv_logger = CSVLogger('logs/smoother/acausal/', name=f'sd_{cfg.seed}_r_y_{cfg.rank_local}_r_b_{cfg.rank_backward}', version='smoother_acausal')\n",
    "ckpt_callback = ModelCheckpoint(save_top_k=3, monitor='r2_valid_enc', mode='max', dirpath='ckpts/smoother/acausal/', save_last=True,\n",
    "                                filename='{epoch:0}_{valid_loss:0.2f}_{r2_valid_enc:0.2f}_{r2_valid_bhv:0.2f}_{valid_bps_enc:0.2f}')\n",
    "\n",
    "seq_vae.ssm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7880b37-078b-4024-87b3-0af955b0d937",
   "metadata": {},
   "source": [
    "## Training and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614378d-3bf3-4954-b532-c0e6f37d4f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = lightning.Trainer(max_epochs=cfg.n_epochs,\n",
    "                            gradient_clip_val=1.0,\n",
    "                            default_root_dir='lightning/',\n",
    "                            callbacks=[ckpt_callback],\n",
    "                            logger=csv_logger,\n",
    "                            )\n",
    "\n",
    "trainer.fit(model=seq_vae, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)\n",
    "torch.save(ckpt_callback.best_model_path, 'ckpts/smoother/acausal/best_model_path.pt')\n",
    "trainer.test(dataloaders=test_dataloader, ckpt_path='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462841f6-257e-4d17-bfb6-47f56c99db05",
   "metadata": {},
   "source": [
    "## Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e68479-0d95-4cb4-8729-3ad1ee949815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"lightning\"\"\"\n",
    "model_ckpt_path = 'ckpts/smoother/acausal/epoch=692_valid_loss=1415.51_r2_valid_enc=0.89_r2_valid_bhv=0.73_valid_bps_enc=0.41.ckpt'\n",
    "seq_vae = LightningMonkeyReaching.load_from_checkpoint(model_ckpt_path, ssm=ssm, cfg=cfg,\n",
    "                                                       n_time_bins_enc=n_time_bins_enc, n_time_bins_bhv=cfg.n_bins_bhv,\n",
    "                                                       strict=False)\n",
    "\"\"\"extract trained ssm from lightning module\"\"\"\n",
    "seq_vae.ssm = seq_vae.ssm.to(cfg.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29257cf-ea39-442a-8641-4541acb7720c",
   "metadata": {},
   "source": [
    "## Evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f58c0e-ddc9-4354-a593-f3e1e739d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_s_train = []\n",
    "z_s_valid = []\n",
    "z_f_valid = []\n",
    "z_p_valid = []\n",
    "stats_valid = []\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    \n",
    "    loss, z, stats = seq_vae.ssm(batch[0], cfg.n_samples)\n",
    "    z_s_train.append(z)\n",
    "\n",
    "for batch in valid_dataloader:\n",
    "    \n",
    "    z_f, stats = seq_vae.ssm.fast_filter_1_to_T(batch[0], cfg.n_samples)\n",
    "    loss, z, stats = seq_vae.ssm(batch[0], cfg.n_samples)\n",
    "    \n",
    "    z_p = seq_vae.ssm.predict_forward(z_f[:, :, 10], cfg.n_samples)\n",
    "    z_p = torch.cat([z_f[:, :, :10], z_p], dim=2)\n",
    "    \n",
    "    z_f_valid.append(z_f)\n",
    "    z_p_valid.append(z_p)\n",
    "    z_s_valid.append(z)\n",
    "    stats_valid.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c88f0-0e74-4823-ad80-268702942459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9fc735-95e0-4cb2-8fd1-19d3580af316",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = torch.svd(seq_vae.ssm.likelihood_pdf.readout_fn[-1].weight.data)\n",
    "V = S.unsqueeze(-1) * V\n",
    "\n",
    "z_s_train = torch.cat(z_s_train, dim=1)\n",
    "z_s_valid = torch.cat(z_s_valid, dim=1)\n",
    "z_f_valid = torch.cat(z_f_valid, dim=1)\n",
    "z_p_valid = torch.cat(z_p_valid, dim=1)\n",
    "\n",
    "z_s_train = z_s_train[..., :cfg.n_latents_read] @ V\n",
    "z_s_test = z_s_valid[..., :cfg.n_latents_read] @ V\n",
    "z_f_test = z_f_valid[..., :cfg.n_latents_read] @ V\n",
    "z_p_test = z_p_valid[..., :cfg.n_latents_read] @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95850c92-3f85-49e4-a6b0-2af26856a8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"colors\"\"\"\n",
    "blues = cm.get_cmap(\"winter\", z_s_test.shape[0])\n",
    "reds = cm.get_cmap(\"summer\", z_s_test.shape[0])\n",
    "springs = cm.get_cmap(\"spring\", z_s_test.shape[0])\n",
    "\n",
    "color_map_list = [blues, reds, springs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c3e9a-27f1-43e3-923a-0da94000b786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial_indcs = np.random.choice(range(0, y_valid_obs.shape[0]), size=4, replace=False)\n",
    "\n",
    "\"\"\"smoothed\"\"\"\n",
    "with torch.no_grad():\n",
    "\n",
    "    fig, axs = plt.subplots(len(trial_indcs), 1, figsize=(4, 6))\n",
    "    \n",
    "    plot_z_samples(fig, axs, z_s_test, trial_indcs, cfg.move_onset, cfg.n_bins_bhv, color_map_list)\n",
    "    \n",
    "    fig.suptitle('latents over time (25 posterior samples x 3 latent x 4 trials)\\n')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    y_min, _ = plt.ylim()\n",
    "    \n",
    "    plt.annotate('movement\\nonset', xy=(cfg.move_onset, y_min), xytext=(cfg.move_onset+3, y_min+0.9*y_min),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "             fontsize=8, ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"filtered\"\"\"\n",
    "with torch.no_grad():\n",
    "\n",
    "    fig, axs = plt.subplots(len(trial_indcs), 1, figsize=(4, 6))\n",
    "    \n",
    "    plot_z_samples(fig, axs, z_f_test, trial_indcs, cfg.move_onset, cfg.n_bins_bhv, color_map_list)\n",
    "    \n",
    "    fig.suptitle('latents over time (25 posterior samples x 3 latent x 4 trials)\\n')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    y_min, _ = plt.ylim()\n",
    "    \n",
    "    plt.annotate('movement\\nonset', xy=(cfg.move_onset, y_min), xytext=(cfg.move_onset+3, y_min+0.9*y_min),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "             fontsize=8, ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\"\"\"predicted\"\"\"\n",
    "with torch.no_grad():\n",
    "\n",
    "    fig, axs = plt.subplots(len(trial_indcs), 1, figsize=(4, 6))\n",
    "    [axs[i].axvline(10, linestyle='--', color='red') for i in range(len(trial_indcs))]\n",
    "    \n",
    "    plot_z_samples(fig, axs, z_p_test, trial_indcs, cfg.move_onset, cfg.n_bins_bhv, color_map_list)\n",
    "\n",
    "    fig.suptitle('latents over time (25 posterior samples x 3 latent x 4 trials)\\n')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    y_min, _ = plt.ylim()\n",
    "                 \n",
    "    plt.annotate('movement\\nonset', xy=(cfg.move_onset, y_min), xytext=(cfg.move_onset+3, y_min+0.9*y_min),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "             fontsize=8, ha='center')\n",
    "        \n",
    "    plt.annotate('prediction\\nstarts', xy=(cfg.n_bins_bhv, y_min), xytext=(cfg.n_bins_bhv-3, y_min+0.9*y_min),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "             fontsize=8, ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0fdb0-78e7-4ee0-93fe-aaea01262d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    trial_idx = np.random.randint(0, n_valid_trials)\n",
    "    \n",
    "    n_trajectories_to_plot = 9\n",
    "    n_latents_to_plot = 3\n",
    "\n",
    "    fig, axes = plt.subplots(int(np.sqrt(n_trajectories_to_plot)), int(np.sqrt(n_trajectories_to_plot)), figsize=(10, 8), subplot_kw={'projection': '3d'})\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f'latent trajectories from trial {trial_idx+1}\\n\\n\\n\\n')\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        \n",
    "        latent1, latent2, latent3 = np.random.choice(range(0, cfg.n_latents_read), size=n_latents_to_plot, replace=False)\n",
    "        \n",
    "        # Select three latent dimensions for 3D plotting\n",
    "        x = torch.tensor(gaussian_filter1d(torch.mean(z_s_test[:, trial_idx, ..., latent1], dim=0), sigma=4, axis=0))\n",
    "        y = torch.tensor(gaussian_filter1d(torch.mean(z_s_test[:, trial_idx, ..., latent2], dim=0), sigma=4, axis=0))\n",
    "        z = torch.tensor(gaussian_filter1d(torch.mean(z_s_test[:, trial_idx, ..., latent3], dim=0), sigma=4, axis=0))\n",
    "\n",
    "        ax.plot(x, y, z, label='smoothed' if i == 0 else '')\n",
    "        \n",
    "        x_p = torch.tensor(gaussian_filter1d(torch.mean(z_p_test[:, trial_idx, ..., latent1], dim=0), sigma=4, axis=0))\n",
    "        y_p = torch.tensor(gaussian_filter1d(torch.mean(z_p_test[:, trial_idx, ..., latent2], dim=0), sigma=4, axis=0))\n",
    "        z_p = torch.tensor(gaussian_filter1d(torch.mean(z_p_test[:, trial_idx, ..., latent3], dim=0), sigma=4, axis=0))\n",
    "        \n",
    "        ax.tick_params(axis='x', labelsize=6)\n",
    "        ax.tick_params(axis='y', labelsize=6)\n",
    "        ax.tick_params(axis='z', labelsize=6)\n",
    "        \n",
    "        ax.plot(x_p, y_p, z_p, label='predicted' if i == 0 else '')\n",
    "        \n",
    "        ax.set_title(f'latents {latent1+1}, {latent2+1}, {latent3+1}', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.6)\n",
    "    \n",
    "    fig.legend(loc='upper center', bbox_to_anchor=(0.5, 0.94), ncol=1, fontsize=7)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bade6-5745-47b2-95df-cbea529e1942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 5), subplot_kw={'projection': '3d'})\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    n_latents_to_plot = 3\n",
    "    n_trajectories_to_plot = 3\n",
    "    \n",
    "    trial_idx = np.random.randint(0, z_s_test.shape[1])\n",
    "    \n",
    "    for i in range(n_trajectories_to_plot):\n",
    "        \n",
    "        # Any random 3 latents\n",
    "        latent1, latent2, latent3 = np.random.choice(range(0, cfg.n_latents_read), size=n_latents_to_plot, replace=False)\n",
    "\n",
    "        # Select three latent dimensions for 3D plotting\n",
    "        x = torch.tensor(\n",
    "            gaussian_filter1d(\n",
    "                torch.mean(\n",
    "                    z_s_test[:, trial_idx, ..., latent1], dim=0), sigma=4, axis=0))\n",
    "        \n",
    "        y = torch.tensor(\n",
    "            gaussian_filter1d(\n",
    "                torch.mean(\n",
    "                    z_s_test[:, trial_idx, ..., latent2], dim=0), sigma=4, axis=0))\n",
    "        \n",
    "        z = torch.tensor(\n",
    "            gaussian_filter1d(\n",
    "                torch.mean(\n",
    "                    z_s_test[:, trial_idx, ..., latent3], dim=0), sigma=4, axis=0))\n",
    "\n",
    "        ax.plot(x, y, z, label=f'latents {latent1+1}, {latent2+1}, {latent3+1}')\n",
    "        \n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    fig.suptitle(f'trial {trial_idx+1}')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0514259d-6a21-4d7c-a6e7-7b7447f1a20a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 5), subplot_kw={'projection': '3d'})\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    n_latents_to_plot = 3\n",
    "    n_trajectories_to_plot = 5\n",
    "    \n",
    "    trials_inds = np.random.choice(range(0, y_valid_obs.shape[0]), size=n_trajectories_to_plot, replace=False)\n",
    "    \n",
    "    # top 3 latents (not indices)\n",
    "    latent1, latent2, latent3 = [0, 1, 2]\n",
    "    \n",
    "    for i in range(n_trajectories_to_plot):\n",
    "\n",
    "        # Select three latent dimensions for 3D plotting\n",
    "        x = torch.tensor(\n",
    "            gaussian_filter1d(\n",
    "                torch.mean(\n",
    "                    z_s_test[:, trials_inds[i], ..., latent1], dim=0), sigma=4, axis=0))\n",
    "        \n",
    "        y = torch.tensor(\n",
    "            gaussian_filter1d(\n",
    "                torch.mean(\n",
    "                    z_s_test[:, trials_inds[i], ..., latent2], dim=0), sigma=4, axis=0))\n",
    "        \n",
    "        z = torch.tensor(\n",
    "            gaussian_filter1d(\n",
    "                torch.mean(\n",
    "                    z_s_test[:, trials_inds[i], ..., latent3], dim=0), sigma=4, axis=0))\n",
    "\n",
    "        ax.plot(x, y, z, label=f'trial {trials_inds[i]+1}')\n",
    "        \n",
    "    ax.legend(fontsize=8)\n",
    "    ax.view_init(elev=20., azim=-35)\n",
    "    ax.set_xlabel('1st latent')\n",
    "    ax.set_ylabel('2nd latent')\n",
    "    ax.set_zlabel('3rd latent')\n",
    "    \n",
    "    fig.suptitle(f'top 3 principal latents')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee6924-8e7a-4179-88f0-ae382e1e6d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading the logs\n",
    "\n",
    "logs_path = 'logs/smoother/acausal/sd_1236_r_y_15_r_b_5/smoother_acausal/metrics.csv'\n",
    "metrics = pd.read_csv(logs_path).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f60980-35b9-4533-b21e-f5be99543c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f297fb-6086-4f66-bb4e-329e942aadc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(\n",
    "    metrics['train_loss'].keys(),\n",
    "    metrics['train_loss'].values(),\n",
    "    marker='o', markersize=2, linestyle='-', color='g', alpha=0.6, linewidth=1, label='train')\n",
    "\n",
    "plt.plot(\n",
    "    metrics['valid_loss'].keys(),\n",
    "    metrics['valid_loss'].values(),\n",
    "    marker='o', markersize=2, linestyle='-', color='y', alpha=0.6, linewidth=1, label='valid')\n",
    "\n",
    "# plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (ELBO)')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb7239-b85f-4175-8758-9b270869121f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(\n",
    "    list(metrics['r2_train_enc'].keys())[1:],\n",
    "    list(metrics['r2_train_enc'].values())[1:],\n",
    "    marker='o', markersize=2, linestyle='-', color='g', alpha=0.6, linewidth=1, label='train')\n",
    "\n",
    "plt.plot(\n",
    "    list(metrics['r2_valid_enc'].keys())[1:],\n",
    "    list(metrics['r2_valid_enc'].values())[1:],\n",
    "    marker='o', markersize=2, linestyle='-', color='y', alpha=0.6, linewidth=1, label='valid')\n",
    "\n",
    "#plt.title('R2')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('r2')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77ed02-ae7a-4bd2-9ea7-a6c92282888f",
   "metadata": {},
   "source": [
    "Another way to evaluate model performance is the **Bits per Spike (BpS)**. Which is a quantification of how neurons encode information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a884d1-603a-4456-a798-88e36c20b400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(\n",
    "    metrics['train_bps_enc'].keys(),\n",
    "    metrics['train_bps_enc'].values(),\n",
    "    marker='o', markersize=2, linestyle='-', color='g', alpha=0.6, linewidth=1, label='train')\n",
    "\n",
    "plt.plot(\n",
    "    metrics['valid_bps_enc'].keys(),\n",
    "    metrics['valid_bps_enc'].values(),\n",
    "    marker='o', markersize=2, linestyle='-', color='y', alpha=0.6, linewidth=1, label='valid')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('bits per spike')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cac625-c865-4388-a366-ee333247a8b3",
   "metadata": {},
   "source": [
    "The previous plots were all about the evolution of the model performance throughout training (loss x epochs). Aonther way to evaluate how the model captures the tuning properties of neurons relative to the stimulus over time is to look at the **peri-stimulus time histogram (PSTH)**.\n",
    "\n",
    "We will generate condition averaged (in our example, conditions are the reaching directions) PSTHs from the model and compare them to the condition averaged PSTHs from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7830851-0e64-4134-ba73-bc5f73d408bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial_indcs = np.random.choice(range(0, y_valid_obs.shape[0]), size=4, replace=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    fig, axs = plt.subplots(len(trial_indcs), 1, figsize=(4, 8))\n",
    "    default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    \n",
    "    plot_z_2d(fig, axs, z_f_test, trial_indcs, cfg.move_onset, cfg.n_bins_bhv, default_colors[0], regime='filtering')\n",
    "    plot_z_2d(fig, axs, z_p_test, trial_indcs, cfg.move_onset, cfg.n_bins_bhv, default_colors[1], regime='prediction')\n",
    "    \n",
    "    #fig.suptitle('First 3 latents over time, for all neurons, from 4 test trials \\n (smoothing regime) \\n')\n",
    "    fig.suptitle('filtered vs predicted\\n\\n\\n\\n')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    y_min, _ = plt.ylim()\n",
    "                 \n",
    "    plt.annotate('movement\\nonset', xy=(cfg.move_onset, y_min), xytext=(cfg.move_onset+3, y_min+0.9*y_min),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "             fontsize=8, ha='center')\n",
    "        \n",
    "    plt.annotate('prediction\\nstarts', xy=(cfg.n_bins_bhv, y_min), xytext=(cfg.n_bins_bhv-3, y_min+0.9*y_min),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "             fontsize=8, ha='center')\n",
    "    \n",
    "    fig.legend(loc='upper center', bbox_to_anchor=(0.47, 0.94), shadow=True, ncol=1, fontsize=6)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d5c16a-24e8-4d5f-814f-39a51c360bb9",
   "metadata": {},
   "source": [
    "# Generating corresponding observations\n",
    "We can use the likelifood function (observation model) to generate new data (log rates) from the latents. And sampele from the rates possion to get the spike counts.\n",
    "\n",
    "Data dimentionality:\\\n",
    "**generated** : sampels x trials x time bins x neurons\\\n",
    "sampels = samples of the latents each of which used to generate the data\\\n",
    "**real**: trials x time bins x neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b12ff9-c7e1-4fc6-ad01-683bd90b3c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# smoothed and predicted log rates\n",
    "r_s = seq_vae.ssm.to(cfg.data_device).likelihood_pdf.readout_fn(z_s_test)\n",
    "r_p = seq_vae.ssm.to(cfg.data_device).likelihood_pdf.readout_fn(z_p_test)\n",
    "# sampeling from the rates possion to get the spike counts\n",
    "y_s = torch.poisson(cfg.bin_sz * torch.exp(r_s))\n",
    "y_p = torch.poisson(cfg.bin_sz * torch.exp(r_p))\n",
    "\n",
    "y_hat = torch.cat([y_s[:, :, :cfg.n_bins_bhv], y_p], dim=2)\n",
    "z_hat = torch.cat([z_s_test[:, :, :cfg.n_bins_bhv, :], z_p_test], dim=2)\n",
    "i = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f24cf9-8484-4f81-ae45-c47a79605c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    trial_idx = np.random.randint(0, y_test_obs.shape[1])\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(4, 6))\n",
    "    plot_spikes(y_test_obs[trial_idx], axs[0])\n",
    "    plot_spikes(y_hat[0, trial_idx], axs[1])\n",
    "\n",
    "    fig.suptitle(f'trial {trial_idx}\\n(active neurons ordered by their spikes count)', fontsize=10)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41651780-26c3-4d18-b601-e56bb9d6764a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " with torch.no_grad():\n",
    "        \n",
    "    neuron_idx = np.random.randint(0, n_neurons_obs)\n",
    "    \n",
    "    y = torch.tensor(gaussian_filter1d(torch.mean(torch.exp(r_s)[0, :, :, neuron_idx], axis=0), sigma=2.5, axis=0))\n",
    "    \n",
    "    plt.plot(np.arange(n_time_bins) * cfg.bin_sz_ms, y)\n",
    "    \n",
    "    plt.title(f'trial-averaged inferred firing rate of neuron {neuron_idx+1}\\n')\n",
    "    plt.xlabel('time (sec)')\n",
    "    plt.ylabel('firing rate')\n",
    "    plt.axvline(x=cfg.move_onset*cfg.bin_sz_ms, color='r', linestyle='--')\n",
    "    plt.annotate('movement\\nonset', xy=(cfg.move_onset*cfg.bin_sz_ms, torch.min(y)), xytext=((cfg.move_onset*cfg.bin_sz_ms)*0.6, torch.min(y)+(torch.max(y)-torch.min(y))*0.05),\n",
    "                     arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "                     fontsize=8, ha='center')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3f3cfd-b70c-4bfe-b17f-d1d7a91c807a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trials_inds = np.random.choice(range(0, y_valid_obs.shape[0]), size=4, replace=False)\n",
    "\n",
    "plot_rastor(y_valid_obs, z_s_test, trials_inds, y_valid_obs.shape[2], cfg)\n",
    "plot_rastor(y_hat[0], z_s_test, trials_inds, y_hat.shape[3], cfg, regime='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f7527-2974-4db8-be46-27ec327996fa",
   "metadata": {},
   "source": [
    "## Ordering the neurons in terms of their loading to the 1st principal latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91935f70-c816-4ee1-b96d-1e27e584a409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial_idx = np.random.randint(0, y_valid_obs.shape[0])\n",
    "ordered_correlations, ordered_neurons = order_neurons(y_valid_obs, z_s_test, trial=trial_idx, latent=0)\n",
    "\n",
    "top_n = 10\n",
    "\n",
    "time_bins = [str(i) for i in ordered_neurons[:top_n].astype('int32')]\n",
    "\n",
    "y = np.abs(ordered_correlations.T[1][:top_n])\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "axes.plot(time_bins, y, marker='o', linestyle='-', color='g')\n",
    "\n",
    "for i in range(len(time_bins)):\n",
    "    plt.text(time_bins[i], y[i]+0.005, f'{y[i]:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    plt.vlines(i, ymin=y.min(), ymax=y[i], linestyles='dashed', colors='gray', alpha=0.5)\n",
    "\n",
    "fig.suptitle(f'top 10 neurons in trial {trial_idx+1} ordered based on their loading\\nto the 1st principal latent dimension\\n\\n\\n\\n')\n",
    "plt.ylim(top=y.max()+0.05*y.max())\n",
    "\n",
    "plt.xlabel('top 10 neurons')\n",
    "plt.ylabel('correlation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599b55d-24c7-4795-994b-26f9965252b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trials_inds = np.random.choice(range(0, y_valid_obs.shape[0]), size=n_trajectories_to_plot, replace=False)\n",
    "\n",
    "plot_rastor(y_valid_obs, z_s_test, trials_inds, y_valid_obs.shape[2], cfg, order=True)\n",
    "plot_rastor(y_hat[0], z_s_test, trials_inds, y_hat.shape[3], cfg, regime='prediction', order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcef989-5585-45fd-be2f-6d03abfdc84f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spike_count = torch.sum(y_valid_obs, axis=1)\n",
    "\n",
    "plt.imshow(spike_count, interpolation='nearest', aspect=0.9)\n",
    "plt.colorbar()\n",
    "plt.title('spike counts\\n')\n",
    "plt.xlabel('neurons')\n",
    "plt.ylabel('trials')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c208c-1c8f-4351-a04e-e7b768619b08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfads",
   "language": "python",
   "name": "xfads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
